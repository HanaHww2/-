{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab-11-3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNNpN0KYfHfcdmb9FB8Q5SB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ipDR0BYJ0qsP"},"source":["# Lab 11-3. MNIST and CNN - Class, Layers, Ensemble"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"XSXwtgWSO2fX","executionInfo":{"status":"ok","timestamp":1610180444395,"user_tz":-540,"elapsed":7700,"user":{"displayName":"Hannah H","photoUrl":"","userId":"15313661666203540641"}},"outputId":"b2510266-83b4-41ce-fe70-418490208905"},"source":["%tensorflow_version 1.x\r\n","import tensorflow as tf\r\n","import matplotlib.pyplot as plt\r\n","from tensorflow.examples.tutorials.mnist import input_data\r\n","tf.__version__"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.15.2'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"zF3PWHLfPz7l"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uF10-rb_MEL5","executionInfo":{"status":"ok","timestamp":1610180449235,"user_tz":-540,"elapsed":2129,"user":{"displayName":"Hannah H","photoUrl":"","userId":"15313661666203540641"}},"outputId":"397c41a7-35b6-4b9e-d17b-17b2986d50cd"},"source":["# gpu 목록 확인\r\n","from tensorflow.python.client import device_lib\r\n","\r\n","for device in device_lib.list_local_devices():\r\n","  print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 4673584146707710334\n","\n","name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 1743150469187954463\n","physical_device_desc: \"device: XLA_CPU device\"\n","\n","name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 16635603418311068583\n","physical_device_desc: \"device: XLA_GPU device\"\n","\n","name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 14912199066\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 6026951940763155801\n","physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t5GwDNvP08pD"},"source":["## 1. Class \r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ZfzlBWv1a40","executionInfo":{"status":"ok","timestamp":1610180456096,"user_tz":-540,"elapsed":1437,"user":{"displayName":"Hannah H","photoUrl":"","userId":"15313661666203540641"}},"outputId":"7dc73242-107f-45a4-a981-c2b26e93fb9b"},"source":["mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\r\n","# Check out https://www.tensorflow.org/get_started/mnist/beginners for\r\n","# more information about the mnist dataset"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-3-e843ee221a27>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use urllib or similar directly.\n","Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.one_hot on tensors.\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IxhABNuL1YUm"},"source":["tf.set_random_seed(777)  # reproducibility"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sWF5iA_X1csc"},"source":["# hyper parameters\r\n","learning_rate = 0.001\r\n","training_epochs = 15\r\n","batch_size = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OUYMs1zw1d9r"},"source":["class Model:\r\n","\r\n","    def __init__(self, sess, name):\r\n","        self.sess = sess\r\n","        self.name = name\r\n","        self._build_net()\r\n","\r\n","    def _build_net(self):\r\n","        with tf.variable_scope(self.name):\r\n","            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1 for testing\r\n","            # self.rate: 1 - keep_prop\r\n","            self.rate = tf.placeholder(tf.float32)\r\n","\r\n","            # input place holders\r\n","            self.X = tf.placeholder(tf.float32, [None, 784])\r\n","            # img 28x28x1 (black/white)\r\n","            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\r\n","            self.Y = tf.placeholder(tf.float32, [None, 10])\r\n","\r\n","            # L1 ImgIn shape=(n, 28, 28, 1)\r\n","            #    Conv     -> (n, 28, 28, 32)\r\n","            #    Pool     -> (n, 14, 14, 32)\r\n","            W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\r\n","            L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\r\n","            L1 = tf.nn.relu(L1)\r\n","            L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\r\n","                                strides=[1, 2, 2, 1], padding='SAME')\r\n","            L1 = tf.nn.dropout(L1, rate= self.rate)\r\n","            '''\r\n","            Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\r\n","            Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\r\n","            Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\r\n","            Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\r\n","            '''\r\n","\r\n","            # L2 ImgIn shape=(n, 14, 14, 32)\r\n","            #    Conv      ->(n, 14, 14, 64)\r\n","            #    Pool      ->(n, 7, 7, 64)\r\n","            W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\r\n","            L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\r\n","            L2 = tf.nn.relu(L2)\r\n","            L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\r\n","                                strides=[1, 2, 2, 1], padding='SAME')\r\n","            L2 = tf.nn.dropout(L2, rate = self.rate)\r\n","            '''\r\n","            Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\r\n","            Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\r\n","            Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\r\n","            Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\r\n","            '''\r\n","\r\n","            # L3 ImgIn shape=(n, 7, 7, 64)\r\n","            #    Conv      ->(n, 7, 7, 128)\r\n","            #    Pool      ->(n, 4, 4, 128)\r\n","            #    Reshape   ->(n, 4 * 4 * 128) # Flatten them for FC\r\n","            W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\r\n","            L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\r\n","            L3 = tf.nn.relu(L3)\r\n","            L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\r\n","                                1, 2, 2, 1], padding='SAME')\r\n","            L3 = tf.nn.dropout(L3, rate = self.rate)\r\n","\r\n","            L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\r\n","            '''\r\n","            Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\r\n","            Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\r\n","            Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\r\n","            Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\r\n","            Tensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\r\n","            '''\r\n","\r\n","            # L4 FC 4x4x128 inputs -> 625 outputs\r\n","            W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\r\n","                                 initializer=tf.contrib.layers.xavier_initializer())\r\n","            b4 = tf.Variable(tf.random_normal([625]))\r\n","            L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\r\n","            L4 = tf.nn.dropout(L4, rate = self.rate)\r\n","            '''\r\n","            Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\r\n","            Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\r\n","            '''\r\n","\r\n","            # L5 Final FC 625 inputs -> 10 outputs\r\n","            W5 = tf.get_variable(\"W5\", shape=[625, 10],\r\n","                                 initializer=tf.contrib.layers.xavier_initializer())\r\n","            b5 = tf.Variable(tf.random_normal([10]))\r\n","            self.logits = tf.matmul(L4, W5) + b5\r\n","            '''\r\n","            Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\r\n","            '''\r\n","\r\n","        # define cost/loss & optimizer\r\n","        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\r\n","            logits=self.logits, labels=self.Y))\r\n","        self.optimizer = tf.train.AdamOptimizer(\r\n","            learning_rate=learning_rate).minimize(self.cost)\r\n","\r\n","        correct_prediction = tf.equal(\r\n","            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\r\n","        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n","\r\n","    def predict(self, x_test, keep_prop=1.0):\r\n","        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.rate: 1 - keep_prop})\r\n","\r\n","    def get_accuracy(self, x_test, y_test, keep_prop=1.0):\r\n","        return self.sess.run(self.accuracy, feed_dict={self.X: x_test, self.Y: y_test, self.rate: 1 - keep_prop})\r\n","\r\n","    def train(self, x_data, y_data, keep_prop=0.7):\r\n","        return self.sess.run([self.cost, self.optimizer], feed_dict={\r\n","            self.X: x_data, self.Y: y_data, self.rate: 1 - keep_prop})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eo3QHPLX0yA_","executionInfo":{"status":"ok","timestamp":1610180519356,"user_tz":-540,"elapsed":54076,"user":{"displayName":"Hannah H","photoUrl":"","userId":"15313661666203540641"}},"outputId":"5cb932b1-380e-4d89-d83e-5f919c553039"},"source":["with tf.device('/device:GPU:0'):\r\n","\r\n","  # initialize\r\n","  sess = tf.Session()\r\n","  m1 = Model(sess, \"m1\")\r\n","  sess.run(tf.global_variables_initializer())\r\n","\r\n","  print('Learning Started!')\r\n","\r\n","  # train my model\r\n","  for epoch in range(training_epochs):\r\n","      avg_cost = 0\r\n","      total_batch = int(mnist.train.num_examples / batch_size)\r\n","\r\n","      for i in range(total_batch):\r\n","          batch_xs, batch_ys = mnist.train.next_batch(batch_size)\r\n","          c, _ = m1.train(batch_xs, batch_ys)\r\n","          avg_cost += c / total_batch\r\n","\r\n","      print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\r\n","\r\n","  print('Learning Finished!')\r\n","\r\n","  # Test model and check accuracy\r\n","  print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","Learning Started!\n","Epoch: 0001 cost = 0.379954391\n","Epoch: 0002 cost = 0.100108019\n","Epoch: 0003 cost = 0.074217026\n","Epoch: 0004 cost = 0.058286154\n","Epoch: 0005 cost = 0.052760926\n","Epoch: 0006 cost = 0.046763152\n","Epoch: 0007 cost = 0.042265379\n","Epoch: 0008 cost = 0.038381906\n","Epoch: 0009 cost = 0.034192960\n","Epoch: 0010 cost = 0.035081773\n","Epoch: 0011 cost = 0.031268516\n","Epoch: 0012 cost = 0.029353426\n","Epoch: 0013 cost = 0.027830957\n","Epoch: 0014 cost = 0.026893484\n","Epoch: 0015 cost = 0.025266407\n","Learning Finished!\n","Accuracy: 0.9929\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iKNTNNEW1n5D"},"source":["## 2. Layers"]},{"cell_type":"code","metadata":{"id":"_rcTsUZ_TT8w"},"source":["tf.reset_default_graph() # 그래프 재시작"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"npujuYtx1nxc"},"source":["tf.set_random_seed(777)  # reproducibility"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vW65Sg5y4Wxx"},"source":["# hyper parameters\r\n","learning_rate = 0.001\r\n","training_epochs = 15\r\n","batch_size = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GxQs4ylX4YDi"},"source":["class Model:\r\n","\r\n","    def __init__(self, sess, name):\r\n","        self.sess = sess\r\n","        self.name = name\r\n","        self._build_net()\r\n","\r\n","    def _build_net(self):\r\n","        with tf.variable_scope(self.name):\r\n","            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\r\n","            # for testing\r\n","            self.training = tf.placeholder(tf.bool)\r\n","\r\n","            # input place holders\r\n","            self.X = tf.placeholder(tf.float32, [None, 784])\r\n","\r\n","            # img 28x28x1 (black/white), Input Layer\r\n","            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\r\n","            self.Y = tf.placeholder(tf.float32, [None, 10])\r\n","\r\n","            # Convolutional Layer #1\r\n","            conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\r\n","                                     padding=\"SAME\", activation=tf.nn.relu)\r\n","            # Pooling Layer #1\r\n","            pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\r\n","                                            padding=\"SAME\", strides=2)\r\n","            dropout1 = tf.layers.dropout(inputs=pool1,\r\n","                                         rate=0.3, training=self.training)\r\n","\r\n","            # Convolutional Layer #2 and Pooling Layer #2\r\n","            conv2 = tf.layers.conv2d(inputs=dropout1, filters=64, kernel_size=[3, 3],\r\n","                                     padding=\"SAME\", activation=tf.nn.relu)\r\n","            pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\r\n","                                            padding=\"SAME\", strides=2)\r\n","            dropout2 = tf.layers.dropout(inputs=pool2,\r\n","                                         rate=0.3, training=self.training)\r\n","\r\n","            # Convolutional Layer #2 and Pooling Layer #2\r\n","            conv3 = tf.layers.conv2d(inputs=dropout2, filters=128, kernel_size=[3, 3],\r\n","                                     padding=\"same\", activation=tf.nn.relu)\r\n","            pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\r\n","                                            padding=\"same\", strides=2)\r\n","            dropout3 = tf.layers.dropout(inputs=pool3,\r\n","                                         rate=0.3, training=self.training)\r\n","\r\n","            # Dense Layer with Relu\r\n","            flat = tf.reshape(dropout3, [-1, 128 * 4 * 4])\r\n","            dense4 = tf.layers.dense(inputs=flat,\r\n","                                     units=625, activation=tf.nn.relu)\r\n","            dropout4 = tf.layers.dropout(inputs=dense4,\r\n","                                         rate=0.5, training=self.training)\r\n","\r\n","            # Logits (no activation) Layer: L5 Final FC 625 inputs -> 10 outputs\r\n","            self.logits = tf.layers.dense(inputs=dropout4, units=10)\r\n","\r\n","        # define cost/loss & optimizer\r\n","        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\r\n","            logits=self.logits, labels=self.Y))\r\n","        self.optimizer = tf.train.AdamOptimizer(\r\n","            learning_rate=learning_rate).minimize(self.cost)\r\n","\r\n","        correct_prediction = tf.equal(\r\n","            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\r\n","        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n","\r\n","    def predict(self, x_test, training=False):\r\n","        return self.sess.run(self.logits,\r\n","                             feed_dict={self.X: x_test, self.training: training})\r\n","\r\n","    def get_accuracy(self, x_test, y_test, training=False):\r\n","        return self.sess.run(self.accuracy,\r\n","                             feed_dict={self.X: x_test,\r\n","                                        self.Y: y_test, self.training: training})\r\n","\r\n","    def train(self, x_data, y_data, training=True):\r\n","        return self.sess.run([self.cost, self.optimizer], feed_dict={\r\n","            self.X: x_data, self.Y: y_data, self.training: training})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S763vfr-1jzJ","executionInfo":{"status":"ok","timestamp":1610180588410,"user_tz":-540,"elapsed":42323,"user":{"displayName":"Hannah H","photoUrl":"","userId":"15313661666203540641"}},"outputId":"43d7fa99-84cd-4270-918f-e710740612f6"},"source":["# initialize\r\n","sess = tf.Session()\r\n","m1 = Model(sess, \"m1\")\r\n","\r\n","sess.run(tf.global_variables_initializer())\r\n","\r\n","print('Learning Started!')\r\n","\r\n","# train my model\r\n","for epoch in range(training_epochs):\r\n","    avg_cost = 0\r\n","    total_batch = int(mnist.train.num_examples / batch_size)\r\n","\r\n","    for i in range(total_batch):\r\n","        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\r\n","        c, _ = m1.train(batch_xs, batch_ys)\r\n","        avg_cost += c / total_batch\r\n","\r\n","    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\r\n","\r\n","print('Learning Finished!')\r\n","\r\n","# Test model and check accuracy\r\n","print('Accuracy:', m1.get_accuracy(mnist.test.images, mnist.test.labels))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-10-31cc24d7ea1d>:23: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.keras.layers.Conv2D` instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From <ipython-input-10-31cc24d7ea1d>:26: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.MaxPooling2D instead.\n","WARNING:tensorflow:From <ipython-input-10-31cc24d7ea1d>:28: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dropout instead.\n","WARNING:tensorflow:From <ipython-input-10-31cc24d7ea1d>:49: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","WARNING:tensorflow:From <ipython-input-10-31cc24d7ea1d>:58: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","Learning Started!\n","Epoch: 0001 cost = 0.292204566\n","Epoch: 0002 cost = 0.090276104\n","Epoch: 0003 cost = 0.067103543\n","Epoch: 0004 cost = 0.056416892\n","Epoch: 0005 cost = 0.048617088\n","Epoch: 0006 cost = 0.046223654\n","Epoch: 0007 cost = 0.040679789\n","Epoch: 0008 cost = 0.038224453\n","Epoch: 0009 cost = 0.035228300\n","Epoch: 0010 cost = 0.033784823\n","Epoch: 0011 cost = 0.032303169\n","Epoch: 0012 cost = 0.031092123\n","Epoch: 0013 cost = 0.029257856\n","Epoch: 0014 cost = 0.028096629\n","Epoch: 0015 cost = 0.025241840\n","Learning Finished!\n","Accuracy: 0.9941\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UnUpcg0Y2cPR"},"source":["## 3. Ensemble layers"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"st0V1g8L2Ym6","executionInfo":{"status":"ok","timestamp":1610181847366,"user_tz":-540,"elapsed":207241,"user":{"displayName":"Hannah H","photoUrl":"","userId":"15313661666203540641"}},"outputId":"3f7d40bf-ccaa-4372-a58c-4ed818c537a7"},"source":["# initialize\r\n","sess = tf.Session()\r\n","\r\n","models = []\r\n","num_models = 5\r\n","for m in range(num_models):\r\n","    models.append(Model(sess, \"model\" + str(m)))\r\n","\r\n","sess.run(tf.global_variables_initializer())\r\n","\r\n","print('Learning Started!')\r\n","\r\n","# train my model\r\n","for epoch in range(training_epochs):\r\n","    avg_cost_list = np.zeros(len(models))\r\n","    total_batch = int(mnist.train.num_examples / batch_size)\r\n","    for i in range(total_batch):\r\n","        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\r\n","\r\n","        # train each model\r\n","        for m_idx, m in enumerate(models):\r\n","            c, _ = m.train(batch_xs, batch_ys)\r\n","            avg_cost_list[m_idx] += c / total_batch\r\n","\r\n","    print('Epoch:', '%04d' % (epoch + 1), 'cost =', avg_cost_list)\r\n","\r\n","print('Learning Finished!')\r\n","\r\n","# Test model and check accuracy\r\n","test_size = len(mnist.test.labels)\r\n","predictions = np.zeros([test_size, 10])\r\n","for m_idx, m in enumerate(models):\r\n","    print(m_idx, 'Accuracy:', m.get_accuracy(\r\n","        mnist.test.images, mnist.test.labels))\r\n","    p = m.predict(mnist.test.images)\r\n","    predictions += p # 예측의 합을 구해서 최대값(라벨)을 결정하는 앙상블\r\n","\r\n","ensemble_correct_prediction = tf.equal(\r\n","    tf.argmax(predictions, 1), tf.argmax(mnist.test.labels, 1))\r\n","ensemble_accuracy = tf.reduce_mean(\r\n","    tf.cast(ensemble_correct_prediction, tf.float32))\r\n","print('Ensemble accuracy:', sess.run(ensemble_accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Learning Started!\n","Epoch: 0001 cost = [0.29619464 0.29385715 0.28502658 0.28186953 0.28567354]\n","Epoch: 0002 cost = [0.0861011  0.08736966 0.08251217 0.08448863 0.08742954]\n","Epoch: 0003 cost = [0.06315293 0.0658391  0.06343973 0.06394202 0.06531296]\n","Epoch: 0004 cost = [0.05853378 0.05672938 0.05492041 0.05680669 0.05685827]\n","Epoch: 0005 cost = [0.04887385 0.0509075  0.04771858 0.04764431 0.050864  ]\n","Epoch: 0006 cost = [0.04433289 0.04361866 0.04297838 0.04477059 0.04405242]\n","Epoch: 0007 cost = [0.03992364 0.03922364 0.04062544 0.03836209 0.04013587]\n","Epoch: 0008 cost = [0.03602006 0.03868274 0.03656459 0.03717121 0.03765183]\n","Epoch: 0009 cost = [0.03240029 0.0354366  0.03480517 0.03666973 0.03523814]\n","Epoch: 0010 cost = [0.03442869 0.03257986 0.03172937 0.03295158 0.03216049]\n","Epoch: 0011 cost = [0.03161256 0.03085668 0.03177774 0.03184036 0.03271207]\n","Epoch: 0012 cost = [0.0290461  0.02944803 0.02836248 0.0318633  0.02953849]\n","Epoch: 0013 cost = [0.02914371 0.02893554 0.02855797 0.029531   0.02822477]\n","Epoch: 0014 cost = [0.02782273 0.02815422 0.02637224 0.02691405 0.02887265]\n","Epoch: 0015 cost = [0.02703999 0.02704528 0.02541567 0.02749333 0.02638139]\n","Learning Finished!\n","0 Accuracy: 0.9932\n","1 Accuracy: 0.9935\n","2 Accuracy: 0.9941\n","3 Accuracy: 0.9932\n","4 Accuracy: 0.9934\n","Ensemble accuracy: 0.9944\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cLICc2rRPpiP","executionInfo":{"status":"ok","timestamp":1610182350387,"user_tz":-540,"elapsed":719,"user":{"displayName":"Hannah H","photoUrl":"","userId":"15313661666203540641"}},"outputId":"77ac2c29-9561-47e2-c03f-96ec6c2f620a"},"source":["# predict 결과값 확인\r\n","import random\r\n","\r\n","r = random.randint(0, mnist.test.num_examples - 1)\r\n","\r\n","for m_idx, m in enumerate(models):\r\n","  print(m.predict(mnist.test.images[r:r + 1])) # predict는 softmax 이전의 logit 값이므로, 크기가 크다\r\n","  break "],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[ -6.5364466  -9.637826  -11.119797    1.0592853  -6.847977   15.735893\n","   -6.6348925  -7.171292   -7.472735    2.3174398]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vD_uFPWsV_Vu","executionInfo":{"status":"ok","timestamp":1610182337562,"user_tz":-540,"elapsed":692,"user":{"displayName":"Hannah H","photoUrl":"","userId":"15313661666203540641"}},"outputId":"15d5267e-6015-430f-d73c-b6bd06843a5b"},"source":["mnist.test.images[1:2].shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 784)"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9z3JirJIVFbo","executionInfo":{"status":"ok","timestamp":1610182105554,"user_tz":-540,"elapsed":652,"user":{"displayName":"Hannah H","photoUrl":"","userId":"15313661666203540641"}},"outputId":"b4331489-bd00-4a07-fde3-35b09d795f41"},"source":["mnist.test.images.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 784)"]},"metadata":{"tags":[]},"execution_count":30}]}]}